{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> PATH II </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickling the Noun_Verb_Noun dataframe with 100 articles of tech and automobile articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = r'data\\Noun-Verb-Noun.pkl'\n",
    "getfile = open(filename, 'rb')\n",
    "kg = pickle.load(getfile)\n",
    "getfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Making the tokens column](#token)<br>\n",
    "2. [Making of Cleaned column by removing cutom stopwords](#stop)<br>\n",
    "3. [Making of Noun Chunks](#nc)<br>\n",
    "**  [Better Way](#better) **\n",
    "4. [Making of edges](#edges)<br>\n",
    "5. [Making of relations](#relations)<br>\n",
    "6. [Trying to make verb phrases using Spacy](#verb)<br>\n",
    "7. [Making of manual check dataframe 1](#manual)<br>\n",
    "** [Manually identifying the correct triples](#identify)<br>\n",
    "8. [Checking all 'of' relations in the triples](#of)<br>\n",
    "9. [Checking all 'in' relations in the triples](#in)<br>\n",
    "10.[df for Graph](#gr)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>a case of the new virus spreading rapidly in c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>disease control officials in wuhan the chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>scientists think the new virus spreading rapid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sam Byford</td>\n",
       "      <td>huawei has announced the postponement of a maj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>the world health organization (who) said today...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                            content\n",
       "0  Nicole Wetsman  a case of the new virus spreading rapidly in c...\n",
       "1  Nicole Wetsman  disease control officials in wuhan the chinese...\n",
       "2  Nicole Wetsman  scientists think the new virus spreading rapid...\n",
       "3      Sam Byford  huawei has announced the postponement of a maj...\n",
       "4  Nicole Wetsman  the world health organization (who) said today..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing neccessary libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy \n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "pd.set_option('display.max_rows',None)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Matcher class object \n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='token'></a>\n",
    "## Creating a tokens column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg['tokens'] = kg.content.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>a case of the new virus spreading rapidly in c...</td>\n",
       "      <td>(a, case, of, the, new, virus, spreading, rapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>disease control officials in wuhan the chinese...</td>\n",
       "      <td>(disease, control, officials, in, wuhan, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>scientists think the new virus spreading rapid...</td>\n",
       "      <td>(scientists, think, the, new, virus, spreading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sam Byford</td>\n",
       "      <td>huawei has announced the postponement of a maj...</td>\n",
       "      <td>(huawei, has, announced, the, postponement, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>the world health organization (who) said today...</td>\n",
       "      <td>(the, world, health, organization, (, who, ), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dieter Bohn</td>\n",
       "      <td>welcome back to processor a mostly daily newsl...</td>\n",
       "      <td>(welcome, back, to, processor, a, mostly, dail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dieter Bohn</td>\n",
       "      <td>happy friday to you! i have been reflecting a ...</td>\n",
       "      <td>(happy, friday, to, you, !, i, have, been, ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>your risk of catching the new coronavirus is p...</td>\n",
       "      <td>(your, risk, of, catching, the, new, coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>a second us case of the new coronavirus has be...</td>\n",
       "      <td>(a, second, us, case, of, the, new, coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mary Beth Griggs</td>\n",
       "      <td>as the coronavirus outbreak continues to sprea...</td>\n",
       "      <td>(as, the, coronavirus, outbreak, continues, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alex Wilhelm</td>\n",
       "      <td>good morning friends and welcome back to techc...</td>\n",
       "      <td>(good, morning, friends, and, welcome, back, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dean Takahashi</td>\n",
       "      <td>plague inc. creator ndemic creations announced...</td>\n",
       "      <td>(plague, inc, ., creator, ndemic, creations, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jeremy Horwitz</td>\n",
       "      <td>as a dangerous coronavirus continues to spread...</td>\n",
       "      <td>(as, a, dangerous, coronavirus, continues, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nick Statt</td>\n",
       "      <td>facebook and gaming hardware maker razer are a...</td>\n",
       "      <td>(facebook, and, gaming, hardware, maker, razer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>as the coronavirus outbreak continues to sprea...</td>\n",
       "      <td>(as, the, coronavirus, outbreak, continues, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nick Statt</td>\n",
       "      <td>apple ceo tim cook said on tuesday that the co...</td>\n",
       "      <td>(apple, ceo, tim, cook, said, on, tuesday, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sean O'Kane</td>\n",
       "      <td>united airlines is suspending some flights to ...</td>\n",
       "      <td>(united, airlines, is, suspending, some, fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nicole Wetsman</td>\n",
       "      <td>the centers for disease control and prevention...</td>\n",
       "      <td>(the, centers, for, disease, control, and, pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nick Statt</td>\n",
       "      <td>taiwanese electronics giant foxconn which manu...</td>\n",
       "      <td>(taiwanese, electronics, giant, foxconn, which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rachel England</td>\n",
       "      <td>in the midst of china's coronavirus outbreak t...</td>\n",
       "      <td>(in, the, midst, of, china, 's, coronavirus, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                            content  \\\n",
       "0     Nicole Wetsman  a case of the new virus spreading rapidly in c...   \n",
       "1     Nicole Wetsman  disease control officials in wuhan the chinese...   \n",
       "2     Nicole Wetsman  scientists think the new virus spreading rapid...   \n",
       "3         Sam Byford  huawei has announced the postponement of a maj...   \n",
       "4     Nicole Wetsman  the world health organization (who) said today...   \n",
       "5        Dieter Bohn  welcome back to processor a mostly daily newsl...   \n",
       "6        Dieter Bohn  happy friday to you! i have been reflecting a ...   \n",
       "7     Nicole Wetsman  your risk of catching the new coronavirus is p...   \n",
       "8     Nicole Wetsman  a second us case of the new coronavirus has be...   \n",
       "9   Mary Beth Griggs  as the coronavirus outbreak continues to sprea...   \n",
       "10      Alex Wilhelm  good morning friends and welcome back to techc...   \n",
       "11    Dean Takahashi  plague inc. creator ndemic creations announced...   \n",
       "12    Jeremy Horwitz  as a dangerous coronavirus continues to spread...   \n",
       "13        Nick Statt  facebook and gaming hardware maker razer are a...   \n",
       "14    Nicole Wetsman  as the coronavirus outbreak continues to sprea...   \n",
       "15        Nick Statt  apple ceo tim cook said on tuesday that the co...   \n",
       "16       Sean O'Kane  united airlines is suspending some flights to ...   \n",
       "17    Nicole Wetsman  the centers for disease control and prevention...   \n",
       "18        Nick Statt  taiwanese electronics giant foxconn which manu...   \n",
       "19    Rachel England  in the midst of china's coronavirus outbreak t...   \n",
       "\n",
       "                                               tokens  \n",
       "0   (a, case, of, the, new, virus, spreading, rapi...  \n",
       "1   (disease, control, officials, in, wuhan, the, ...  \n",
       "2   (scientists, think, the, new, virus, spreading...  \n",
       "3   (huawei, has, announced, the, postponement, of...  \n",
       "4   (the, world, health, organization, (, who, ), ...  \n",
       "5   (welcome, back, to, processor, a, mostly, dail...  \n",
       "6   (happy, friday, to, you, !, i, have, been, ref...  \n",
       "7   (your, risk, of, catching, the, new, coronavir...  \n",
       "8   (a, second, us, case, of, the, new, coronaviru...  \n",
       "9   (as, the, coronavirus, outbreak, continues, to...  \n",
       "10  (good, morning, friends, and, welcome, back, t...  \n",
       "11  (plague, inc, ., creator, ndemic, creations, a...  \n",
       "12  (as, a, dangerous, coronavirus, continues, to,...  \n",
       "13  (facebook, and, gaming, hardware, maker, razer...  \n",
       "14  (as, the, coronavirus, outbreak, continues, to...  \n",
       "15  (apple, ceo, tim, cook, said, on, tuesday, tha...  \n",
       "16  (united, airlines, is, suspending, some, fligh...  \n",
       "17  (the, centers, for, disease, control, and, pre...  \n",
       "18  (taiwanese, electronics, giant, foxconn, which...  \n",
       "19  (in, the, midst, of, china, 's, coronavirus, o...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stop'></a>\n",
    "## Making of cleaned column by editing spacy stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg[\"cleaned\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(len(spacy_stopwords)) ## just copying the stopwords to create a new set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stp = {'ten', 'former', 'while', 'thence', 'if', 'being', 'afterwards', 'elsewhere', \\\n",
    "       'when', 'whereby', 'me', 'our', 'did', 'moreover', 'ca', 'besides', 'upon', 'very',\\\n",
    "       'hence', 'put', \"'ll\", 'seem', 'cannot', 'call', 'therein', 'using', 'he', 'between',\\\n",
    "       'can', 'meanwhile', 'latterly', 'whereafter', 'than', 'mostly', 'during', 'until', \\\n",
    "       'nothing', 'too', 'was', 'seeming', 'across', 'get', 'from', 'both', 'n’t', 'your', \\\n",
    "       'whether', 'six', 'although', 'does', 'beforehand', 'amongst', 'wherein', 'her', 'be',\\\n",
    "       \"'ve\", 'however', 'perhaps', 'along', 'above', 'name', 'something', '’m', 'another',\\\n",
    "       'everyone', 'any', 'eleven', 'itself', 'two', 'whence', 'were', 'much', 'anyway', \\\n",
    "       'someone', 'quite', 'always', 'seems', 'alone', 'out', 'whenever', 'fifteen', 'forty',\\\n",
    "       'there', 'amount', 'each', 'what', 'have', 'nine', 'thru', 'still', 'really', 'myself',\\\n",
    "       'thereby', 'sometimes', 'nowhere', 'below', 'am', 'nobody', 'those', 'move', 'wherever',\\\n",
    "       'would', 'the', 'see', 'no', 'together', 'do', '‘m', 'here', 'are', 'even', 'neither', \\\n",
    "       'to', 'him', 'must', 'twelve', 'throughout', 'once', 'one', 'among', 'yours', 'thereupon',\\\n",
    "       'but', 'who', 'latter', 'not', 'indeed', 'noone', 'towards', \"n't\", 'somewhere', 'with',\\\n",
    "       'just', 'less', 'my', 'could', 'becomes', 'these', 'every', 'few', 'his', 'doing', 'else',\\\n",
    "       'they', 'nevertheless', 'hundred', 'on', 'toward', 'rather', '’ll', 'since', 'also',\\\n",
    "       'which', 'hereupon', 'beside', 'made', 'or', 'herself', 'otherwise', 'become', 'will',\\\n",
    "       'is', 'whereas', 'several', 'at', 'about', 'now', 'an', 'under', 'around', 'sixty', \\\n",
    "       'all', 'full', 'others', 'other', 'its', 'behind', 'them', 'many', 'why', 'that', 'give', \\\n",
    "       'mine', 'hereby', 'three', 'without', 'namely', 'everything', 'might', 'never', 'only', \\\n",
    "       'so', '’ve', 'almost', \"'m\", 'onto', 'whither', 'front', 'us', 'next', 'seemed', 'fifty',\\\n",
    "       'has', 'further', 'whose', 'go', 'after', 'anyhow', 'for', 'serious', 'this', 'none',\\\n",
    "       'regarding', 'before', 'we', 'how', '’s', 'then', 'somehow', 'thus', 'becoming', 'whom',\\\n",
    "       'herein', 'third', 'may', 'against', '‘d', 'except', 'by', 'hereafter', 'into', 'first',\\\n",
    "       'well', 'twenty', 'should', 'unless', 'whole', 'it', 'most', '’re', '’d', 'through',\\\n",
    "       'within', 'had', 'everywhere', 'been', 'keep', 're', 'ours', 'whatever', 'hers', \\\n",
    "       'therefore', 'of', 'sometime', 'beyond', 'as', 'more', 'where', 'take', 'used',\\\n",
    "       'anywhere', 'because', 'own', 'up', 'yet', 'himself', 'i', 'again', 'either', \\\n",
    "       'anything', 'done', 'various', '‘ve', 'last', 'a', '‘s', 'please', 'via', 'same', \\\n",
    "       'she', \"'s\", 'show', 'eight', 'top', 'side', 'and', 'though', 'their', 'became', \\\n",
    "       'ourselves', 'ever', 'thereafter', 'back', 'say', 'least', 'bottom', 'often', '‘re', \\\n",
    "       'n‘t', 'such', 'off', 'make', 'whoever', 'empty', \"'d\", 'you', 'whereupon', 'per', 'nor',\\\n",
    "       'enough', 'formerly', 'four', 'part', 'down', 'due', 'some', 'five', 'yourselves', \\\n",
    "       'yourself', 'anyone', \"'re\", 'over', 'themselves', '‘ll', 'already'}\n",
    "\n",
    "len(stp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp.discard('in')   ## discard doesnt throw and error if the given item is not in the set. it will keept the set as is. \n",
    "stp.discard('from')\n",
    "stp.discard('of')\n",
    "stp.discard('six')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaned column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(len(kg.tokens)):    \n",
    "    for tok in kg.tokens[doc]:\n",
    "        if tok not in stp:                                    #.is_stop\n",
    "            kg.cleaned[doc] += str(tok)+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a case of the new virus spreading rapidly in china has been reported in a patient in seattle washing'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.cleaned[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nc'></a>\n",
    "## Making of Noun Chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_chunks_01234 = []\n",
    "\n",
    "\n",
    "for i in [0,1,2,3,4]:\n",
    "    for chunk in nlp(kg.cleaned[i]).noun_chunks: #or in [patterns]\n",
    "        noun_chunks_01234.append(chunk)\n",
    "        ##add ADP+PROPN+NUM or NUM+PROPN or PROPN+NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_chunks_01234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent1 = noun_chunks_01234[::2] #even ids of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent2 = noun_chunks_01234[1::2] #odd ids of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent1 = ent1[0:365]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_01234 = []\n",
    "\n",
    "vp = ['VERB'] \n",
    "\n",
    "for i in [0,1,2,3,4]:\n",
    "    for each in nlp(kg.cleaned[i]):\n",
    "        if each.pos_ in vp:\n",
    "            verbs_01234.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verbs_01234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[spreading, reported, reports, returned, monitored]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_01234[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3242"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kg.cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a case of the new virus spreading rapidly in china has been reported in a patient in seattle washington reuters reports . the patient had recently returned from china and is clinically healthy but still being monitored . this is the first us case of the virus which was first detected in wuhan a city in central china in late december 2019 . it has already sickened around 300 people and killed six . despite the case report the centers for disease control and prevention ( cdc ) said during a press '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.cleaned[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent1</th>\n",
       "      <th>verb</th>\n",
       "      <th>ent2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(a, case)</td>\n",
       "      <td>spreading</td>\n",
       "      <td>(the, new, virus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(china)</td>\n",
       "      <td>reported</td>\n",
       "      <td>(a, patient)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(seattle, washington, reuters)</td>\n",
       "      <td>reports</td>\n",
       "      <td>(the, patient)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(china)</td>\n",
       "      <td>returned</td>\n",
       "      <td>(the, first, us, case)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(the, virus)</td>\n",
       "      <td>monitored</td>\n",
       "      <td>(wuhan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(a, city)</td>\n",
       "      <td>detected</td>\n",
       "      <td>(central, china)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(late, december)</td>\n",
       "      <td>sickened</td>\n",
       "      <td>(it)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(around, 300, people)</td>\n",
       "      <td>killed</td>\n",
       "      <td>(the, case)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(the, centers)</td>\n",
       "      <td>report</td>\n",
       "      <td>(disease, control)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(prevention)</td>\n",
       "      <td>said</td>\n",
       "      <td>((, cdc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(a, press, briefing)</td>\n",
       "      <td>believe</td>\n",
       "      <td>(they)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(the, threat)</td>\n",
       "      <td>remains</td>\n",
       "      <td>(the, us)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(the, virus)</td>\n",
       "      <td>known</td>\n",
       "      <td>(the, designation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(it)</td>\n",
       "      <td>indicates</td>\n",
       "      <td>(a, coronavirus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(the, family)</td>\n",
       "      <td>caused</td>\n",
       "      <td>(viruses)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(the, sars, outbreak)</td>\n",
       "      <td>killed</td>\n",
       "      <td>(that, outbreak)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(nearly, 800, people)</td>\n",
       "      <td>bringing</td>\n",
       "      <td>(me)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(timothy)</td>\n",
       "      <td>flashbacks</td>\n",
       "      <td>(a, coronavirus, expert)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(assistant, professor)</td>\n",
       "      <td>says</td>\n",
       "      <td>(the, university)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(north, carolina)</td>\n",
       "      <td>flew</td>\n",
       "      <td>(gillings, school)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ent1        verb                      ent2\n",
       "0                        (a, case)   spreading         (the, new, virus)\n",
       "1                          (china)    reported              (a, patient)\n",
       "2   (seattle, washington, reuters)     reports            (the, patient)\n",
       "3                          (china)    returned    (the, first, us, case)\n",
       "4                     (the, virus)   monitored                   (wuhan)\n",
       "5                        (a, city)    detected          (central, china)\n",
       "6                 (late, december)    sickened                      (it)\n",
       "7            (around, 300, people)      killed               (the, case)\n",
       "8                   (the, centers)      report        (disease, control)\n",
       "9                     (prevention)        said                  ((, cdc)\n",
       "10            (a, press, briefing)     believe                    (they)\n",
       "11                   (the, threat)     remains                 (the, us)\n",
       "12                    (the, virus)       known        (the, designation)\n",
       "13                            (it)   indicates          (a, coronavirus)\n",
       "14                   (the, family)      caused                 (viruses)\n",
       "15           (the, sars, outbreak)      killed          (that, outbreak)\n",
       "16           (nearly, 800, people)    bringing                      (me)\n",
       "17                       (timothy)  flashbacks  (a, coronavirus, expert)\n",
       "18          (assistant, professor)        says         (the, university)\n",
       "19               (north, carolina)        flew        (gillings, school)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_01234 = pd.DataFrame({'ent1':ent1[0:365],'verb':verbs_01234[0:365],'ent2':ent2})\n",
    "df_01234[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_01234.to_csv(\"Noun_chunks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'data/Noun-chunks.pkl'\n",
    "#out = open(filename,'wb')\n",
    "\n",
    "#pickle.dump(df_012,out)\n",
    "#out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above dataframe is not accurately able to detect the triples. (We getting only 4-5 triples from 25 rows). Thus, next we will look into improving our algorithm to capture more triples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='edge'></a>\n",
    "## Making of edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[a case, the new virus, china, a patient]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_chunks_01234[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a case, the new virus, china, a patient, seattle washington reuters, the patient, china, the first us case, the virus, wuhan]\n",
      "[the new virus, china, a patient, seattle washington reuters, the patient, china, the first us case, the virus, wuhan, a city]\n"
     ]
    }
   ],
   "source": [
    "edge_1 = noun_chunks_01234[0::]\n",
    "print(edge_1[:10])\n",
    "edge_2 = noun_chunks_01234[1::]\n",
    "print(edge_2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a case, the new virus, china, a patient, seattle washington reuters, the patient, china, the first us case, the virus, wuhan]\n",
      "[the new virus, china, a patient, seattle washington reuters, the patient, china, the first us case, the virus, wuhan, a city]\n"
     ]
    }
   ],
   "source": [
    "edge1 = noun_chunks_01234[0::]\n",
    "print(edge1[:10])\n",
    "edge2 = noun_chunks_01234[1::]\n",
    "print(edge2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='relations'></a>\n",
    "## Making of relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_ = []\n",
    "\n",
    "vp = ['VERB','ADP'] \n",
    "\n",
    "for i in [0,1,2,3,4]:\n",
    "    for each in nlp(kg.cleaned[i]):\n",
    "        if each.pos_ in vp:\n",
    "            relations_.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730\n",
      "730\n",
      "729\n"
     ]
    }
   ],
   "source": [
    "print(len(edge_1))\n",
    "print(len(relations_))\n",
    "print(len(edge_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a case, the new virus, china, a patient, seattle washington reuters]\n",
      "[of, spreading, in, reported, in]\n",
      "[the new virus, china, a patient, seattle washington reuters, the patient]\n"
     ]
    }
   ],
   "source": [
    "print(edge_1[:5])\n",
    "print(relations_[:5])\n",
    "print(edge_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a case of the new virus spreading rapidly in china has been reported in a patient in seattle washington reuters reports. the patient had recently returned from china and is clinically healthy but still being monitored. this is the first us case of the virus which was first detected in wuhan a city i'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.content[0][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='verb'></a>\n",
    "## Trying to make verb phrases using Spacy Matcher: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(sent):\n",
    "    doc = nlp(sent)\n",
    "    verb_list=[]\n",
    "  # Matcher class object \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "  #AUX-VERB-ADV-ADP: \n",
    "    pattern = [{'POS':'AUX','OP':\"?\"},\n",
    "               {'POS':'VERB'},   \n",
    "               {'POS':'ADV','OP':\"?\"},\n",
    "               {'POS':'ADP','OP':\"?\"}] \n",
    "\n",
    "    \n",
    "    matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "    matches = matcher(doc)\n",
    "    #print(matches)\n",
    "    for i in range(len(matches)-1):\n",
    "        if doc[matches[i][1]] != doc[matches[i+1][1]]:\n",
    "            span = doc[matches[i][1]:matches[i][2]] \n",
    "        #print('----',span)\n",
    "            verb_list.append(span.text)\n",
    "    #print(verb_list)\n",
    "    return(verb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrb_all=[]\n",
    "for doc in range(len(kg.content)-1):\n",
    "    a = get_relation(kg.content[doc])\n",
    "    #print(a)\n",
    "    if a != '':\n",
    "        vrb_all.append(a)\n",
    "\n",
    "vrb_all = sum(vrb_all,[item for items in vrb_all for item in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent1</th>\n",
       "      <th>verb</th>\n",
       "      <th>ent2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(a, case)</td>\n",
       "      <td>spreading rapidly in</td>\n",
       "      <td>(the, new, virus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(china)</td>\n",
       "      <td>been reported in</td>\n",
       "      <td>(a, patient)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(seattle, washington, reuters)</td>\n",
       "      <td>reported in</td>\n",
       "      <td>(the, patient)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(china)</td>\n",
       "      <td>reports</td>\n",
       "      <td>(the, first, us, case)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(the, virus)</td>\n",
       "      <td>returned from</td>\n",
       "      <td>(wuhan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(a, city)</td>\n",
       "      <td>being monitored</td>\n",
       "      <td>(central, china)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(late, december)</td>\n",
       "      <td>monitored</td>\n",
       "      <td>(it)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(around, 300, people)</td>\n",
       "      <td>detected in</td>\n",
       "      <td>(the, case)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(the, centers)</td>\n",
       "      <td>sickened around</td>\n",
       "      <td>(disease, control)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(prevention)</td>\n",
       "      <td>killed</td>\n",
       "      <td>((, cdc)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ent1                  verb  \\\n",
       "0                       (a, case)  spreading rapidly in   \n",
       "1                         (china)      been reported in   \n",
       "2  (seattle, washington, reuters)           reported in   \n",
       "3                         (china)               reports   \n",
       "4                    (the, virus)         returned from   \n",
       "5                       (a, city)       being monitored   \n",
       "6                (late, december)             monitored   \n",
       "7           (around, 300, people)           detected in   \n",
       "8                  (the, centers)       sickened around   \n",
       "9                    (prevention)                killed   \n",
       "\n",
       "                     ent2  \n",
       "0       (the, new, virus)  \n",
       "1            (a, patient)  \n",
       "2          (the, patient)  \n",
       "3  (the, first, us, case)  \n",
       "4                 (wuhan)  \n",
       "5        (central, china)  \n",
       "6                    (it)  \n",
       "7             (the, case)  \n",
       "8      (disease, control)  \n",
       "9                ((, cdc)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_01234_verbph = pd.DataFrame({'ent1':ent1,'verb':vrb_all[0:365],'ent2':ent2})\n",
    "df_01234_verbph[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2356062832825383259 Match1 91 93 press briefing\n",
      "2356062832825383259 Match1 121 124 family of viruses\n",
      "2356062832825383259 Match1 151 153 coronavirus expert\n",
      "2356062832825383259 Match1 227 229 hospital staff\n",
      "2356062832825383259 Match1 252 254 health screenings\n",
      "2356062832825383259 Match1 319 321 health officials\n",
      "2356062832825383259 Match1 331 334 threats from coronaviruses\n",
      "2356062832825383259 Match1 390 393 sars for example\n",
      "2356062832825383259 Match1 405 407 seafood market\n",
      "2356062832825383259 Match1 450 452 health authorities\n",
      "2356062832825383259 Match1 478 480 animal reservoir\n",
      "2356062832825383259 Match1 498 501 human to human\n",
      "2356062832825383259 Match1 541 543 health emergency\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(kg.content[0])\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# This is a triple and can define a relationship\n",
    "pattern1 = [{'POS': 'NOUN','OP':'+'},\n",
    "            {'POS': 'ADP','OP':'?'},\n",
    "            {'POS': 'NOUN','OP':'+'}] \n",
    "\n",
    "matcher.add('Match1', None, pattern1) # add the pattern to the matcher \n",
    "matches = matcher(doc)\n",
    "#print(matches)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:<br>We would like to add the above findings into our dataset but this is not something which we can use to build datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='manual'></a>\n",
    "## Making of manual checking dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N1</th>\n",
       "      <th>relations</th>\n",
       "      <th>N2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(a, case)</td>\n",
       "      <td>of</td>\n",
       "      <td>(the, new, virus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(the, new, virus)</td>\n",
       "      <td>spreading</td>\n",
       "      <td>(china)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(china)</td>\n",
       "      <td>in</td>\n",
       "      <td>(a, patient)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(a, patient)</td>\n",
       "      <td>reported</td>\n",
       "      <td>(seattle, washington, reuters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(seattle, washington, reuters)</td>\n",
       "      <td>in</td>\n",
       "      <td>(the, patient)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(the, patient)</td>\n",
       "      <td>in</td>\n",
       "      <td>(china)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(china)</td>\n",
       "      <td>reports</td>\n",
       "      <td>(the, first, us, case)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(the, first, us, case)</td>\n",
       "      <td>returned</td>\n",
       "      <td>(the, virus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(the, virus)</td>\n",
       "      <td>from</td>\n",
       "      <td>(wuhan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(wuhan)</td>\n",
       "      <td>monitored</td>\n",
       "      <td>(a, city)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(a, city)</td>\n",
       "      <td>of</td>\n",
       "      <td>(central, china)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(central, china)</td>\n",
       "      <td>detected</td>\n",
       "      <td>(late, december)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(late, december)</td>\n",
       "      <td>in</td>\n",
       "      <td>(it)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(it)</td>\n",
       "      <td>in</td>\n",
       "      <td>(around, 300, people)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(around, 300, people)</td>\n",
       "      <td>in</td>\n",
       "      <td>(the, case)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(the, case)</td>\n",
       "      <td>sickened</td>\n",
       "      <td>(the, centers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(the, centers)</td>\n",
       "      <td>killed</td>\n",
       "      <td>(disease, control)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(disease, control)</td>\n",
       "      <td>report</td>\n",
       "      <td>(prevention)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(prevention)</td>\n",
       "      <td>for</td>\n",
       "      <td>((, cdc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>((, cdc)</td>\n",
       "      <td>said</td>\n",
       "      <td>(a, press, briefing)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                N1  relations                              N2\n",
       "0                        (a, case)         of               (the, new, virus)\n",
       "1                (the, new, virus)  spreading                         (china)\n",
       "2                          (china)         in                    (a, patient)\n",
       "3                     (a, patient)   reported  (seattle, washington, reuters)\n",
       "4   (seattle, washington, reuters)         in                  (the, patient)\n",
       "5                   (the, patient)         in                         (china)\n",
       "6                          (china)    reports          (the, first, us, case)\n",
       "7           (the, first, us, case)   returned                    (the, virus)\n",
       "8                     (the, virus)       from                         (wuhan)\n",
       "9                          (wuhan)  monitored                       (a, city)\n",
       "10                       (a, city)         of                (central, china)\n",
       "11                (central, china)   detected                (late, december)\n",
       "12                (late, december)         in                            (it)\n",
       "13                            (it)         in           (around, 300, people)\n",
       "14           (around, 300, people)         in                     (the, case)\n",
       "15                     (the, case)   sickened                  (the, centers)\n",
       "16                  (the, centers)     killed              (disease, control)\n",
       "17              (disease, control)     report                    (prevention)\n",
       "18                    (prevention)        for                        ((, cdc)\n",
       "19                        ((, cdc)       said            (a, press, briefing)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'N1':edge_1[0:729],'relations':relations_[0:729],'N2':edge_2[0:729]}\n",
    "\n",
    "manual_check_1 = pd.DataFrame(data)\n",
    "manual_check_1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual_check_1.to_csv('manual_check_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on the new triples dataframe to understand its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 729 entries, 0 to 728\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   N1         729 non-null    object\n",
      " 1   relations  729 non-null    object\n",
      " 2   N2         729 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "manual_check_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_check_1.N1 = manual_check_1.N1.astype('str')\n",
    "manual_check_1.relations = manual_check_1.relations.astype('str')\n",
    "manual_check_1.N2 = manual_check_1.N2.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 729 entries, 0 to 728\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   N1         729 non-null    object\n",
      " 1   relations  729 non-null    object\n",
      " 2   N2         729 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "manual_check_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='identify'></a>\n",
    "## Manually identifying the correct triples:<br>\n",
    "1. [Checking all 'of' relations in the triples](#of)<br>\n",
    "2. [Checking all 'in' relations in the triples](#in)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='of'></a>\n",
    "## 'of' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "of_df = manual_check_1[manual_check_1.relations=='of'].reset_index()\n",
    "len(of_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(of_df[0::2])   ## -> 42% (15/35) accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(42+44)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(of_df[1::2]) ## 15/34 44% correct triples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy for triples with 'of' relation: 0.435 %\n"
     ]
    }
   ],
   "source": [
    "print('Total accuracy for triples with \\'of\\' relation:',round(30/69,3),'%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N1           this kind\n",
       "relations           of\n",
       "N2           emergency\n",
       "Name: 679, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_check_1.iloc[679]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='in'></a>\n",
    "## 'in' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_df = manual_check_1[manual_check_1.relations=='in'].reset_index()\n",
    "len(in_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_df[0::2])   ## -> 26.47% (9/34) accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_df[1::2]) ## 19/34 55.88% correct triples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy for triples with 'in' relation: 0.412 %\n"
     ]
    }
   ],
   "source": [
    "print('Total accuracy for triples with \\'in\\' relation:',round(28/68,3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "69+68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N1</th>\n",
       "      <th>relations</th>\n",
       "      <th>N2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this kind</td>\n",
       "      <td>of</td>\n",
       "      <td>emergency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the aggressive efforts</td>\n",
       "      <td>of</td>\n",
       "      <td>chinese officials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>any additional restrictions</td>\n",
       "      <td>of</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kristian andersen director</td>\n",
       "      <td>of</td>\n",
       "      <td>infectious disease genomics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the full genetic sequence</td>\n",
       "      <td>of</td>\n",
       "      <td>the virus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            N1 relations                           N2\n",
       "0                    this kind        of                    emergency\n",
       "1       the aggressive efforts        of            chinese officials\n",
       "2  any additional restrictions        of                       travel\n",
       "3   kristian andersen director        of  infectious disease genomics\n",
       "4    the full genetic sequence        of                    the virus"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = [679,706,727,347,444,524,528,565,575,0,37,103,217,299,307,10,36,\\\n",
    "          229,318,406,439,492,515,526,564,675,683,704,707,715,10,36,229,318,406,439,\\\n",
    "          492,515,526,564,675,683,704,707,715,5,165,374,388,392,442,530,688,712,4,\\\n",
    "          87,161,322,328,336,345,373,378,383,389,395,432,472,534,556,600,642,685,717]\n",
    "print(len(correct))\n",
    "\n",
    "for each in [0,1,3,9,12,13,16,18,19,20,23,24,27,28,29,30,31,32,33,37,39,40,42,44,45,46,49,\\\n",
    "            50,51,52,53,56,57,59,61,64,67,68,71,74,76, 84, 89, 100, 105, 110, 113, 114, 116,\\\n",
    "            117,124,127,141,144,156,166,178,179,184,186,187,188,189,190,193]:\n",
    "        \n",
    "        if each in correct:\n",
    "            pass\n",
    "        else:\n",
    "            correct.append(each)\n",
    "print(len(correct))\n",
    "            \n",
    "df_correct_1 = [manual_check_1.iloc[each] for each in correct]   # -- 1\n",
    "\n",
    "df_correct_1 = pd.DataFrame(df_correct_1).reset_index(drop=True) \n",
    "df_correct_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_correct_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manual_check_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'in' in manual_check_1.relations: ##to avoid errors, we know it should be 661\n",
    "    manual_check_1.drop(manual_check_1[manual_check_1.relations=='in'].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manual_check_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(manual_check_1)>592: ##to avoid errors, we know it should be 592\n",
    "    manual_check_1.drop(manual_check_1[manual_check_1.relations=='of'].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manual_check_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N1</th>\n",
       "      <th>relations</th>\n",
       "      <th>N2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the new virus</td>\n",
       "      <td>spreading</td>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china</td>\n",
       "      <td>in</td>\n",
       "      <td>a patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a patient</td>\n",
       "      <td>reported</td>\n",
       "      <td>seattle washington reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seattle washington reuters</td>\n",
       "      <td>in</td>\n",
       "      <td>the patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the patient</td>\n",
       "      <td>in</td>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>china</td>\n",
       "      <td>reports</td>\n",
       "      <td>the first us case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the first us case</td>\n",
       "      <td>returned</td>\n",
       "      <td>the virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the virus</td>\n",
       "      <td>from</td>\n",
       "      <td>wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wuhan</td>\n",
       "      <td>monitored</td>\n",
       "      <td>a city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>central china</td>\n",
       "      <td>detected</td>\n",
       "      <td>late december</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            N1  relations                          N2\n",
       "1                the new virus  spreading                       china\n",
       "2                        china         in                   a patient\n",
       "3                    a patient   reported  seattle washington reuters\n",
       "4   seattle washington reuters         in                 the patient\n",
       "5                  the patient         in                       china\n",
       "6                        china    reports           the first us case\n",
       "7            the first us case   returned                   the virus\n",
       "8                    the virus       from                       wuhan\n",
       "9                        wuhan  monitored                      a city\n",
       "11               central china   detected               late december"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_check_1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#gr'></a>\n",
    "## Making the graph on df_correct_1 triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_correct_1.N1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_correct_1.N1.unique()) ## We have 57 unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes = np.append(df_correct_1.N1,df_correct_1.N2)\n",
    "len(all_nodes)\n",
    "len(np.unique(all_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a dictionary with the unique values:\n",
    "all_nodes = {value:key for (key,value) in dict(enumerate(np.unique(all_nodes),0)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a new column with the encoded keys for N1 column: \n",
    "df_correct_1['key_n1'] = df_correct_1['N1'].copy(deep=True).map(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_correct_1.key_n1.isna()) ## checking if there are any NaN values in the key_n1 column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a new column with the encoded keys for N2 column: \n",
    "df_correct_1['key_n2'] = df_correct_1['N2'].copy(deep=True).map(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_correct_1.key_n2.isna()) ## checking if there are any NaN values in the key_n1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N1</th>\n",
       "      <th>relations</th>\n",
       "      <th>N2</th>\n",
       "      <th>key_n1</th>\n",
       "      <th>key_n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this kind</td>\n",
       "      <td>of</td>\n",
       "      <td>emergency</td>\n",
       "      <td>147</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the aggressive efforts</td>\n",
       "      <td>of</td>\n",
       "      <td>chinese officials</td>\n",
       "      <td>93</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>any additional restrictions</td>\n",
       "      <td>of</td>\n",
       "      <td>travel</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kristian andersen director</td>\n",
       "      <td>of</td>\n",
       "      <td>infectious disease genomics</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the full genetic sequence</td>\n",
       "      <td>of</td>\n",
       "      <td>the virus</td>\n",
       "      <td>109</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            N1 relations                           N2  key_n1  \\\n",
       "0                    this kind        of                    emergency     147   \n",
       "1       the aggressive efforts        of            chinese officials      93   \n",
       "2  any additional restrictions        of                       travel      23   \n",
       "3   kristian andersen director        of  infectious disease genomics      62   \n",
       "4    the full genetic sequence        of                    the virus     109   \n",
       "\n",
       "   key_n2  \n",
       "0      40  \n",
       "1      33  \n",
       "2     155  \n",
       "3      57  \n",
       "4     141  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct_1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating keys to get all the keys from both the entity columns:\n",
    "keys = np.unique(np.append(df_correct_1.key_n1,df_correct_1.key_n2))\n",
    "keys[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['( cdc', '17 people', '2019 ) zika', 'a case'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Corresponding names of the keys:\n",
    "name = np.unique(np.append(df_correct_1.N1,df_correct_1.N2))\n",
    "name[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the nodes dataframe from unique values in the data:\n",
    "dfNodes = pd.DataFrame.from_dict(all_nodes,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( cdc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17 people</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019 ) zika</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a case</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  keys\n",
       "0        ( cdc     0\n",
       "1    17 people     1\n",
       "2  2019 ) zika     2\n",
       "3       a case     3"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNodes = dfNodes.reset_index().rename(columns={'index':'name',0:'keys'})\n",
    "dfNodes[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNodes = dfNodes.reindex(columns=['keys','name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the links and the nodes data to csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_1.to_csv(r'data\\Links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNodes.to_csv(r'data\\Nodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling the links and nodes dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/Links.pkl'\n",
    "out = open(filename,'wb')\n",
    "\n",
    "pickle.dump(df_correct_1,out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/Nodes.pkl'\n",
    "out = open(filename,'wb')\n",
    "\n",
    "pickle.dump(dfNodes,out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We prepared the Links and Nodes csv files for our NetworkD3 graph R script next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
